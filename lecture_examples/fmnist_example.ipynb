{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import cv2\n",
    "from imutils import build_montages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[INFO] loading Fashion MNIST...\n"
     ]
    }
   ],
   "source": [
    "# grab the Fashion MNIST dataset (if this is your first time running\n",
    "# this the dataset will be automatically downloaded)\n",
    "print(\"[INFO] loading Fashion MNIST...\")\n",
    "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
    "\n",
    "# use \"channels last\" ordering, so the design\n",
    "# matrix shape should be: num_samples x rows x columns x depth\n",
    "# channels last is the default format in tf.  \n",
    "# it can be changed by editing ~/.keras/keras.json or\n",
    "# specifying the the data_format in the conv2D layers\n",
    "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "\n",
    "# scale data to the range of [0, 1]\n",
    "trainX = trainX.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0\n",
    "\n",
    "# one-hot encode the training and testing labels\n",
    "trainY = to_categorical(trainY, 10)\n",
    "testY = to_categorical(testY, 10)\n",
    "\n",
    "# initialize the label names\n",
    "labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n",
    "\"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_path = 'data/fmnist_cnn.hdf5'\n",
    "\n",
    "assert os.path.isfile(model_path), print(f'File not found at: {model_path}')\n",
    "    \n",
    "model = load_model(model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show some test images\n",
    "\n",
    "# initialize our list of output images\n",
    "images = []\n",
    "\n",
    "# randomly select a few testing fashion items\n",
    "for i in np.random.choice(np.arange(0, len(testY)), size=(16,)):\n",
    "    # classify the clothing\n",
    "    probs = model.predict(testX[np.newaxis, i])\n",
    "    prediction = probs.argmax(axis=1)\n",
    "    label = labelNames[prediction[0]]\n",
    "    \n",
    "    image = (testX[i] * 255).astype(\"uint8\")\n",
    "\n",
    "    # initialize the text label color as green (correct)\n",
    "    color = (0, 255, 0)\n",
    "\n",
    "    # otherwise, the class label prediction is incorrect\n",
    "    if prediction[0] != np.argmax(testY[i]):\n",
    "        color = (0, 0, 255)\n",
    "    \n",
    "    # merge the channels into one image and resize the image from\n",
    "    # 28x28 to 96x96 so we can better see it and then draw the\n",
    "    # predicted label on the image\n",
    "    image = cv2.merge([image] * 3)\n",
    "    image = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
    "    cv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75,\n",
    "        color, 2)\n",
    "\n",
    "    # add the image to our list of output images\n",
    "    images.append(image)\n",
    "\n",
    "# construct the montage for the images\n",
    "montage = build_montages(images, (96, 96), (4, 4))[0]\n",
    "written = cv2.imwrite('img/fashion_mnist.png', montage)\n",
    "\n"
   ]
  },
  {
   "source": [
    "![montage](img/fashion_mnist.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_number = np.random.randint(len(testX))\n",
    "class_probabilities = model.predict(np.expand_dims(testX[img_number], 0))\n",
    "\n",
    "N_classes = 10\n",
    "class_probabilities = class_probabilities.reshape(N_classes)\n",
    "class_decision = np.argmax(class_probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Probability of class[0]:   1.227e-02\nProbability of class[1]:   5.907e-06\nProbability of class[2]:   1.289e-04\nProbability of class[3]:   9.832e-01 :: <class decision>\nProbability of class[4]:   4.875e-04\nProbability of class[5]:   1.085e-06\nProbability of class[6]:   3.873e-03\nProbability of class[7]:   8.644e-06\nProbability of class[8]:   3.540e-06\nProbability of class[9]:   3.105e-06\n\nCorrect class: 3\n\nCORRECT classification\n"
     ]
    }
   ],
   "source": [
    "for m in range(N_classes):\n",
    "    if m == class_decision: \n",
    "        print(f'Probability of class[{m}]:  {class_probabilities[m] : 5.3e} :: <class decision>')\n",
    "    else:\n",
    "        print(f'Probability of class[{m}]:  {class_probabilities[m] : 5.3e}')\n",
    "\n",
    "correct_class = np.argmax(testY[img_number])\n",
    "print(f'\\nCorrect class: {correct_class}\\n')\n",
    "if correct_class != class_decision:\n",
    "    print('INCORRECT classification')\n",
    "else:\n",
    "    print('CORRECT classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}