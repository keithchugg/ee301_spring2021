{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "import soundfile as sf"
   ]
  },
  {
   "source": [
    "**Audio Filtering example:**  Below is a routine that will allow you to change the filtering ranges easily."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_freq_respone(b, a, x_low=0, x_high=0.5, y_low=-60, y_high=0, freq_tag='', freq_scale=1):\n",
    "    ## this computes the arma filter's frequency response from the diff. eq. coefficents\n",
    "    w, H = signal.freqz(b, a, worN=2**16)\n",
    "    \n",
    "    plt.figure()\n",
    "    nu =  ( w / ( 2 * np.pi ) ) \n",
    "    plt.plot(nu * freq_scale, 20 * np.log10(abs(H)), label='|H| (dB)')\n",
    "    plt.legend()\n",
    "    plt.grid(linestyle=':')\n",
    "    xlims = np.asarray([x_low, x_high]) * freq_scale\n",
    "    plt.xlim()\n",
    "    plt.ylim([y_low, y_high])\n",
    "    plt.xlabel(f'frequency {freq_tag}')\n",
    "    plt.ylabel('filter gain (dB)')\n",
    "\n",
    "def filter_and_plot_audio(f_cut_hz, filter_order, fname):\n",
    "    ## read the wav file\n",
    "    x, f_sample = sf.read(fname)\n",
    "\n",
    "    nu_0 = f_cut_hz / f_sample\n",
    "    b, a = signal.butter(filter_order, 2 * nu_0)\n",
    "    plot_freq_respone(b, a, freq_tag='(kHz)', freq_scale=f_sample/1000)\n",
    "\n",
    "    y = signal.lfilter(b, a, x)\n",
    "    N_samples = len(x)\n",
    "    t = np.arange(N_samples) / f_sample\n",
    "    plt.figure()\n",
    "    plt.plot(t, x, color = 'tab:gray', label='input') # linewidth=1,\n",
    "    plt.plot(t, y, color = 'r', label='output')\n",
    "    plt.legend()\n",
    "    plt.grid(linestyle=':')\n",
    "    plt.xlabel(\"time (sec)\")\n",
    "    plt.ylabel(\"signals\")\n",
    "    # plt.xlim([0, 100])\n",
    "    plt.ylim([-1, 1])\n",
    "    plt.show()\n",
    "    #plt.savefig('toy.png', dpi=256)\n",
    "    \n",
    "    return y, f_sample\n"
   ]
  },
  {
   "source": [
    "There are two audio files.  First, is a recording of me where I speak for a few seconds and then I (try to) whistle.  Let's filter out frequencies above 2 kHz and see what it sounds like.  This will look for a file called ``chugg_welcome.wav`` in a directory called ``data`` in this working directory.  If you are on windows, you will have to adjust the path definitions accordingly."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_cut = 2000\n",
    "y_chirp, f_sample = filter_and_plot_audio(f_cut, 4, 'data/chugg_welcome.wav')\n",
    "sf.write(f'data/chugg_welcome_{f_cut}.wav', y_chirp, f_sample)"
   ]
  },
  {
   "source": [
    "Check out the spectrogram.  The top one is for the original file and the bottom one is for the filtered file.  The original was recorded using an apple wired headset, which has a smapling frequency of 44.1 kHz, so the maximum frequency that it can record is 22.05 kHz.  Note in the spectrograms that there are no high frequencies in the filter output -- you should be able to hear that too!  Note that a spectrogram is an advanced concept which shwos the frequency content as a function of time (we shall see why this is an advanced concept!)\n",
    "\n",
    "![Spectrograms for Audio Example 1](img/chugg_welcome_spctrogram.png)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "As an aside, here is a zoomed in picture at lower frequencies.  Note that there are specific patterns associated with the speech taht are visiable in a spectrogram.  Speech recognition systems are designed to spot the differences in these patterns for different sounds in our speech -- i.e., these spectrograms are typically the inputs to an automatic speech recognition engine. \n",
    "\n",
    "Also, see how the whstle is close to a pure tone at about 1.7 kHz? \n",
    "\n",
    "![Spectrograms for Audio Example 1](img/chugg_welcome_low_freqs.png)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "OK, lets check out the second audio file which is `chirp.wav`.  This was generated using Audcity's built-in tools -- i.e., see the `Generate` menu.  A chip is a sine wave with frequency that increaces linearly over time.  For example, the frequency at time $t$ is $f(t) = \\beta t$.  Then, the chirp signal is\n",
    "\n",
    "$$x_c(t) = \\cos( 2 \\pi f(t) t) = \\cos( 2 \\pi \\beta t^2) $$\n",
    "\n",
    "When you listen to this, you will hear a tone that slowly increases frequency.  \n",
    "\n",
    "Let's filter it to filter out frequencies above 4 kHz and plot the input and output.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_cut = 4000\n",
    "y_chirp, f_sample = filter_and_plot_audio(f_cut, 4, 'data/chirp.wav')\n",
    "sf.write(f'data/chirp_{f_cut}.wav', y_chirp, f_sample)\n"
   ]
  },
  {
   "source": [
    "Notice in the above plot that the output is close to zero once the input frequency exceeds the filter cut-off frequency of 4 kHz. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Let's take a look at the spectrograms from Audacity for this as well.  The top is the input chirp and the bottom is the output -- again note that the higher frequencies are attenuated by the filter.  \n",
    "\n",
    "![Spectrograms for Audio Example 1](img/chip_spectrogram.png)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}